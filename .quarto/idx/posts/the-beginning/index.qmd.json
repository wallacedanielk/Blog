{"title":"Using Scikit Learn and SMOTE To Identify Employee Attrition","markdown":{"yaml":{"title":"Using Scikit Learn and SMOTE To Identify Employee Attrition","author":"Daniel Wallace","date":"2023-04-10","categories":["machine Learning","Python"],"image":"cogs.jpg"},"containsRefs":false,"markdown":"\n<div>\n<h3> Why are we here? </h3>\n<p>\n&emsp; Every employer, at one point or another, faces employee turnover. Given the cost of recruiting a new employee,\non-boarding, training, and the learning curve that a new employee faces to be able to bring value to their new position,\nbeing able to prevent the loss of a seasoned employee holds value to the employer.\n</p>\n<p>\n&emsp; We are going to look at a publicily availble dataset that is popular on Kaggle (<a href=https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset> Available Here </a>) and walk through preprocessing, feature selection, oversampling, and finally classification of the label class. \n</p>\n<h3>It is all about the data </h3>\n<p>\n\nThere is a little bit of prep that needs to be done before we dig into the data and code. If you would like to follow along, here is a link to the python environment file that I used in this research: <a href=\"https://github.com/wallacedanielk/fileHosting/blob/main/environment.yml\">Here is my environment File.</a>\n\n&emsp; The IBM HR Attrition data set is a fictional dataset created by IBM scientists. This dataset has been used in multiple papers and in various\nnotebooks on the Kaggle competition website. The attrition dataset has 1470 rows, with 35 columns . The label in this\ncase is yes or no, where yes implies that the employee has left the organization and no implies that they stayed. The\n’yes’ result is 84% of the data and the ’no’ result is 16%.\n</p>\n\n\n![First we are going to import all required libraries for this analysis](importImage.png){width=80%}\n\nTo load the dataset you can read it in using Pandas, I call my data variable attritionData.  \n\n![Before I get started I split my data into a dataset of features and an array of labels.](dataSplit.png){width=80%}\n\n\n<h3>Time for a little housekeeping</h3>\n\n\n![Labels are encoded using 1 for 'yes' and 0 for 'no'](encode.png){width=80%} \n\n![Columns 'Over18', 'EmployeeCount', 'Standard Hours' were dropped due to having the same value for all of the records in the dataset.The Column 'EmployeeNumber' was dropped due to it being a unique identifier for each record and offers no value to the model.](removeColumns.png){width=30%} \n\n![This dataset did not have any missing value, so no techniques for missing data were used. The above code will verify that.](missing.png){width=80%} \n \n![ All categorical variables were one-hot encoded using the 'dummies' Pandas package in Python.](oneHot.png){width=80%} \n \n ![The continous features were scaled using standard scalar from Scikit Learn package in Python. I implement this in a method that we will call on the data.](scaleMethod.png){width=80%}\n\n ![Then you call the method that we created on the data, and get the columns for later use. ](scaleMethodUsed.png){width=80%}\n\n ![The dataset was split into training as testing data using a 70/30 split. ](dataSplitTestTrain.png){width=80%}\n\n\n\n\n\n\nThe testing data was not resampled to provide a clean test dataset to test the algorithms against. \n\n\n<h3>Selecting the right features</h3>\n\n ![Columns were dropped based on feature importances with a threshold of 0.015 ](importances.png){width=80%}\n\n![The above section of code keeps only the 'important' columns](ColToKeep.png){width=80%}\n\n<h3>Creating new data from old data</h3>\n\n ![The training data was resampled using borderline SMOTE. ](resample.png){width=80%}\n\n\n\n<h3>Classifying the data</h3>\n \n\n ![We are using various machine learning models,  here we intialize the classifier and fit the models. ](classifierFit.png){width=80%}\n\n ![Now we make predictions](predictions.png){width=80%}\n\n<h3>The Wrap Up</h3>\n</div>\n\n\n\n\n\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"index.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","theme":"cosmo","title-block-banner":true,"title":"Using Scikit Learn and SMOTE To Identify Employee Attrition","author":"Daniel Wallace","date":"2023-04-10","categories":["machine Learning","Python"],"image":"cogs.jpg"},"extensions":{"book":{"multiFile":true}}}}}