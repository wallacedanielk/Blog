[
  {
    "objectID": "posts/the-beginning/index.html",
    "href": "posts/the-beginning/index.html",
    "title": "Using Scikit Learn and SMOTE To Identify Employee Attrition",
    "section": "",
    "text": "Why are we here?\n\n\n  Every employer, at one point or another, faces employee turnover. Given the cost of recruiting a new employee, on-boarding, training, and the learning curve that a new employee faces to be able to bring value to their new position, being able to prevent the loss of a seasoned employee holds value to the employer.\n\n\n  We are going to look at a publicily availble dataset that is popular on Kaggle ( Available Here ) and walk through preprocessing, feature selection, oversampling, and finally classification of the label class.\n\n\nIt is all about the data\n\n\nThere is a little bit of prep that needs to be done before we dig into the data and code. If you would like to follow along, here is a link to the python environment file that I used in this research: Here is my environment File.\n  The IBM HR Attrition data set is a fictional dataset created by IBM scientists. This dataset has been used in multiple papers and in various notebooks on the Kaggle competition website. The attrition dataset has 1470 rows, with 35 columns . The label in this case is yes or no, where yes implies that the employee has left the organization and no implies that they stayed. The ’yes’ result is 84% of the data and the ’no’ result is 16%.\n\n\n\n\nFirst we are going to import all required libraries for this analysis\n\n\nTo load the dataset you can read it in using Pandas, I call my data variable attritionData.\n\n\n\nBefore I get started I split my data into a dataset of features and an array of labels.\n\n\n\nTime for a little housekeeping\n\n\n\n\nLabels are encoded using 1 for ‘yes’ and 0 for ‘no’\n\n\n\n\n\nColumns ‘Over18’, ‘EmployeeCount’, ‘Standard Hours’ were dropped due to having the same value for all of the records in the dataset.The Column ‘EmployeeNumber’ was dropped due to it being a unique identifier for each record and offers no value to the model.\n\n\n\n\n\nThis dataset did not have any missing value, so no techniques for missing data were used. The above code will verify that.\n\n\n\n\n\nAll categorical variables were one-hot encoded using the ‘dummies’ Pandas package in Python.\n\n\n\n\n\nThe continous features were scaled using standard scalar from Scikit Learn package in Python. I implement this in a method that we will call on the data.\n\n\n\n\n\nThen you call the method that we created on the data, and get the columns for later use.\n\n\n\n\n\nThe dataset was split into training as testing data using a 70/30 split.\n\n\nThe testing data was not resampled to provide a clean test dataset to test the algorithms against.\n\nSelecting the right features\n\n\n\n\nColumns were dropped based on feature importances with a threshold of 0.015\n\n\n\n\n\nThe above section of code keeps only the ‘important’ columns\n\n\n\nCreating new data from old data\n\n\n\n\nThe training data was resampled using borderline SMOTE.\n\n\n\nClassifying the data\n\n\n\n\nWe are using various machine learning models, here we intialize the classifier and fit the models.\n\n\n\n\n\nNow we make predictions\n\n\n\nHow do we know if the predictions are Good?\n\n\n\n\nWe use precision, recall, f1-score, and accuracy\n\n\n\n\n\nThe above metrics are calculated using a contingency table. Here is an example of one using our Logistic Regression Predictions\n\n\n\n\n\nAnother metric that you can use is the Area under the ROC Curve\n\n\n\n\n\nThe code above produces a grphic like this one\n\n\n\nThe Wrap Up\n\nWe walked through the analysis from data import all the way through testing the classification results. You should be able to conduct your own analysis or extend mine to meet your needs. After going through all of the above, on all of my classifiers I achieved the following results:\nTo determine the best classification model to use to predict employee attrition we compare the metrics that were defined above. Of the Non-Smote samples, Random Forest has a better average precision than all of the other models. XGBoost has the best average recall. Both XGBoost and Random forest in the Non-SMOTE re-sampling category have accuracy of 0.86. Depending on which level of errors you can live with in your research will allow you to choose either Random Forest or XBBoost for your attrition data. When comparing re-sampling vs not re-sampling we are again divided. Random Forest and XGBoost both had better average precision, however the SMOTE re-sampling datasets yielded a better average recall. The accuracy was the same for both re-sampled and non re-sampled. Again, if your research is looking to maximize average recall, then SMOTE re-sampling with Random Forest is the best classification algorithm to use. This dataset was relatively small, you also have to consider the computational complexity of SMOTE re-sampling to determine if the trade off is worth any gains that you may make in average recall. In comparing most of the classification algorithms in this research, SMOTE resampling underperformed the classification done with non-SMOTE re-sampled data. Looking at the ROC Curve in figure 3 we can also see the advantage in using the non-SMOTE sampled dataset for classification."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning Project",
    "section": "",
    "text": "Using Scikit Learn and SMOTE To Identify Employee Attrition\n\n\n\n\n\n\n\nmachine Learning\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nApr 10, 2023\n\n\nDaniel Wallace\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This blog is about a machine learning project I worked on during my Masters degree at UWF."
  }
]