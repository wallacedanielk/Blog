[
  {
    "objectID": "posts/the-beginning/index.html",
    "href": "posts/the-beginning/index.html",
    "title": "Using Scikit Learn and SMOTE To Identify Employee Attrition",
    "section": "",
    "text": "Why are we here?\n\n\n  Every employer, at one point or another, faces employee turnover. Given the cost of recruiting a new employee, on-boarding, training, and the learning curve that a new employee faces to be able to bring value to their new position, being able to prevent the loss of a seasoned employee holds value to the employer.\n\n\n  We are going to look at a publicily availble dataset that is popular on Kaggle (https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset.) and walk through preprocessing, feature selection, oversampling, and finally classification of the label class.\n\n\nIt is all about the data\n\n\n  The IBM HR Attrition data set is a fictional dataset created by IBM scientists. This dataset has been used in multiple papers and in various notebooks on the Kaggle competition website. The attrition dataset has 1470 rows, with 35 columns . The label in this case is yes or no, where yes implies that the employee has left the organization and no implies that they stayed. The ’yes’ result is 84% of the data and the ’no’ result is 16%.\n\n\nTime for a little housekeeping\n\n\n\nLabels were encoded using 1 for ‘yes’ and 0 for ‘no’\n\n\nColumns ‘Over18’, ‘EmployeeCount’, ‘Standard Hours’ were dropped due to all having the same value for all of the records in the dataset.\n\n\nThe Column ‘EmployeeNumber’ was dropped due to it being a unique identifier for each record and offers no value to the model.\n\n\nThis dataset did not have any missing value, so no techniques for missing data were used.\n\n\nAll categorical variables were one-hot encoded using the ‘dummies’ Pandas package in Python.\n\n\nThe continous features were scaled using standard scalar from Scikit Learn package in Python\n\n\nColumns were dropped based on feature importances with a threshold of 0.015\n\n\nThe dataset was split into training as testing data using a 70/30 split.\n\n\nThe training data was resampled using borderline SMOTE. The testing data was not resampled to provide a clean test dataset to test the algorithms against.\n\n\n\nSelecting the right features\n\n\n  Above I briefly talked about dropping columns and selecting features, here is where we will dive into that in a little more detail.\n\n\nCreating new data from old data\n\n\n  SMOTE\n\n\nClassifying the data\n\n\nThe Wrap Up"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning Project",
    "section": "",
    "text": "Using Scikit Learn and SMOTE To Identify Employee Attrition\n\n\n\n\n\n\n\nmachine Learning\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nApr 10, 2023\n\n\nDaniel Wallace\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This blog is about a machine learning project I worked on during my Masters degree at UWF."
  }
]